### Question 1: 

# In this question we will evaluate type I and type II error probabilities for one-sided tests. We will consider normally distributed data, with unit variance and independent obervations. We will use H0 : µ = 0 for the null and H1 : µ = 1 for the alternative, unless otherwise stated.

> Task a

## Suppose we have n = 6 observations x1,...,x6. What is the sampling distribution of the sample mean (that is, of ba(x) = 1/6(x_1 +··· + x_6)?)

In the theory, the sample mean of $x_1,..,x_6$ which are considered in standard Gaussian $N(0,1)$ should be like this:
\begin{equation}
\overline{x}\sim N\left( 0,\frac{1}{\sqrt{6}}\right)
\end{equation}
Some of the variability of this sample mean can be produced by:
```{r}
mean(rnorm(6))
```
```{r}
mean(rnorm(6))
```
```{r}
mean(rnorm(6))
```

Plot the distribution of all the variability in R.
```{r}
width <- 0.05
n <- 100000
sample_means <- replicate(n,mean(rnorm(6)))
hist(sample_means,breaks=seq(from=-2,to=2,by=width),col='pink')
```

Verify the output if it match with the theory:
```{r}
width <- 0.05
n <- 100000
sample_means <- replicate(n,mean(rnorm(6)))
hist(sample_means,breaks=seq(from=-2,to=2,by=width),col='pink')
x <- seq(from=-2,to=2,len=100)
points(x,n*width*dnorm(x,sd=1/sqrt(6)),type="l",lwd=6)
legend("topleft",lwd=c(6,12),col=c("black","pink"),legend=c("theory","numerical"))
```

The distribution met the theory basically, we can consider that the distribution produced by R is reliable.
<br><br/>

> Task b

# We want a test with size α = 0.05. This test is to be of the form “reject H0 if the sample mean x exceeds T ” (where T is a value to be determined).You will recall that α is the probability of rejecting H0 when true. Find an appropriate value of T .

Find a test with $α = 0.05$, the value of T which is reflected in $P(X < T) = 0.95$ is helpful to obtain a line to divide the option between rejection and fail rejection for the null. 
```{r}
qnorm(0.95,mean=0,sd=1/sqrt(6))
```

Hence, T = 0.6715087. The working principle of $P(X < 0.67) = 0.95$ one-sided tests in this sample $N\left(0,\frac{1}{\sqrt{6}}\right)$ can be plotted.
```{r}
plot(x,dnorm(x,sd=1/sqrt(6)),type='l')
abline(v=qnorm(0.95,sd=1/sqrt(6)))
```

On the right side of dividing line, the test will reject the null, and it will be fail to reject the null on the left probability area. 
We test the frequency of rejection.
```{r}
table(replicate(1000,mean(rnorm(6))>0.67))
```

We can notice when the null is ture we reject it rarely (about 5%). The p-value can be calculate by:
```{r}
pnorm(mean(rnorm(6)),mean=0,sd=1/sqrt(6),lower.tail=FALSE)
```

Verify the p-value.
```{r}
hist(replicate(1000,pnorm(mean(rnorm(6)),sd=1/sqrt(6))))
```

The p-value is uniformly distributed, therefore, the probability of it being less than 0.05 is 0.05.
<br><br/>

> Task c

# Calculate β, the probability of failing to reject the null hypothesis when the alternative is true, and state the power of the test.

To calculate $\beta$ which is the probability of failing to reject the null hypothesis when the alternative $H_1:\mu=1$ is true.
```{r}
table(replicate(10000,mean(rnorm(6,mean=1))>qnorm(0.95,sd=1/sqrt(6))))
```

$\beta$ is about 0.78 and the power ($1-\beta$) is about 0.22. We can calculate the power exactly:
```{r}
pnorm(qnorm(0.95,sd=1/sqrt(6)),mean=1,sd=1/sqrt(6))
```

The power of the test is about 0.21.
Verify it in the picture.
```{r}
plot(x,dnorm(x,sd=1/sqrt(6)),type='l')
points(x,dnorm(x,mean=1,sd=1/sqrt(6)),col='red',type='l')
abline(v=qnorm(0.95,sd=1/sqrt(6)))
```
<br><br/>

> Task d

# Consider a test of size α = 0.01. Calculate the power of this test.

When $\alpha=0.01$, the power of this test should be:
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(6)),mean=1,sd=1/sqrt(6),lower.tail=FALSE)
```

It is 0.54.
<br><br/>

> Task e

#  How many observations would it take to have a size of at most 0.01 and a power of at least 0.99?

We can notice that with the growth of observations, the power of the test would be increasing.
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(7)),mean=1,sd=1/sqrt(7),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(8)),mean=1,sd=1/sqrt(8),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(9)),mean=1,sd=1/sqrt(9),lower.tail=FALSE)
```

When the amount of observations is 22, it will meet the power at least 0.99.
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(22)),mean=1,sd=1/sqrt(22),lower.tail=FALSE)
```
<br><br/>

> Task f

# Now we will consider the case where the null and alternative hypotheses are very close. We will have H0 : µ = 0 but now H1 : µ = 0.02. Now how many observations are needed to ensure α is at most 0.01 and the power is at least 0.99?

Plot a graph in terms of the relation between observation and power in order to narrow the range for search. It looks like this.
```{r}
x <- seq(from=0,to=100000,len=100000)
plot(x,pnorm(qnorm(0.99,sd=1/sqrt(1:100000)),mean=0.02,sd=1/sqrt(1:100000),lower.tail=FALSE),xlab="Observation", ylab="Power")
abline(h=0.99)
```

It can be seen from the output. More than 5e+04 observations are required to meet the power close to 0.99. Then, we use trial-and-error method to find a suitable number of observations based on this condition. We start from 50000 observations.
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(50000)),mean=0.02,sd=1/sqrt(50000),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(52000)),mean=0.02,sd=1/sqrt(52000),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54000)),mean=0.02,sd=1/sqrt(54000),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(56000)),mean=0.02,sd=1/sqrt(56000),lower.tail=FALSE)
```

56000 is too much. Reduce observations.
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(55000)),mean=0.02,sd=1/sqrt(55000),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54800)),mean=0.02,sd=1/sqrt(54800),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54600)),mean=0.02,sd=1/sqrt(54600),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54400)),mean=0.02,sd=1/sqrt(54400),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54200)),mean=0.02,sd=1/sqrt(54200),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54100)),mean=0.02,sd=1/sqrt(54100),lower.tail=FALSE)
```

It is between 54100 and 54200.
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54110)),mean=0.02,sd=1/sqrt(54110),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54120)),mean=0.02,sd=1/sqrt(54120),lower.tail=FALSE)
```

It is between 54110 and 54120.
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54119)),mean=0.02,sd=1/sqrt(54119),lower.tail=FALSE)
```
```{r}
pnorm(qnorm(0.99,sd=1/sqrt(54118)),mean=0.02,sd=1/sqrt(54118),lower.tail=FALSE)
```

It needs 54119 observations to ensure $\alpha$ is at most 0.01 and the power is at least 0.99.

### Question 2: 

# This question will consider likelihood values for the Gaussian distribution. Use your student ID to set the random number seed, then take a sample of size 5 from the standard (mean zero, standard deviation 1) Gaussian distribution:
```{r}
> set.seed(1266402) # this is my student ID; you use yours!
> x <- rnorm(5)
```

> Task a

# Using R commands similar to
# prod(dnorm(x,mean=1,sd=2))
# sum(dnorm(x,mean=1,sd=2,log=TRUE))
# Calculate the log-likelihoods for:
• mean=0,sd=1;
• mean=0,sd=1.1;
• mean=0.1,sd=1
• mean=0.1,sd=1.1.
# State which one is the most likely.

Set the random number seed firstly.
```{r}
set.seed(18035793)
x<- rnorm(5)
```

The log-likelihood for 'mean=0, sd=1':
```{r}
prod(dnorm(x,mean=0,sd=1,log=TRUE))
```
The log-likelihood for 'mean=0, sd=1.1':
```{r}
prod(dnorm(x,mean=0,sd=1.1,log=TRUE))
```
The log-likelihood for 'mean=0.1, sd=1':
```{r}
prod(dnorm(x,mean=0.1,sd=1,log=TRUE))
```
The log-likelihood for 'mean=0.1, sd=1':
```{r}
prod(dnorm(x,mean=0.1,sd=1.1,log=TRUE))
```

The log-likelihood for mean = 0 and sd = 1 is the most likely situation, because it shows the least negative logarithm of the likelihood.
<br><br/>

> Task b

# Find an (approximate!) maximum likelihood estimate for the mean and standard deviation. Use trial-and-error; determine the mean first, on the assuption that the SD=1. Then determine the standard deviation, using your value of the mean. Two decimal places are fine.

Firstly, we plot a support function to seek the feasible range of maximum likelihood.
```{r}
support <- function(m){sum(dnorm(x,mean=m,log=TRUE))}  # support function
m <- seq(from=-8,to=8,len=100)    # range of plausible population means
plot(m,sapply(m,support))        # plot the support
abline(v=mean(x))  
```

The mean is between $(0,-1)$. Subsequently, the method trial-and-error is used to find the precise maximum likelihood estimate. We start from mean=0, sd=1.
```{r}
prod(dnorm(x,mean=0,sd=1))
```

The growth of sample mean will decrease the likelihood estimate.
```{r}
prod(dnorm(x,mean=1,sd=1))
```

Narrowing sample mean will not change the likelihood estimate obviously.
```{r}
prod(dnorm(x,mean=1e-08,sd=1))
```

A negative value of mean can make the likelihood improved.
```{r}
prod(dnorm(x,mean=-0.1,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.2,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.3,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.4,sd=1))
```

The result went wrose when mean equal -0.5.
```{r}
prod(dnorm(x,mean=-0.5,sd=1))
```

or even mean=-0.41
```{r}
prod(dnorm(x,mean=-0.41,sd=1))
```

Aquire an optimal solution.
```{r}
prod(dnorm(x,mean=-0.39,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.38,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.37,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=1))
```
```{r}
prod(dnorm(x,mean=-0.35,sd=1))
```

The performance went wrose when mean = -0.35. Therefore, mean = -0.36 is access to the maximum of likelihood estimate. Next, determine the standard deviation.

```{r}
prod(dnorm(x,mean=-0.36,sd=0.9))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=0.8))
```

The solution is between $sd ∈ [0.9,0.8]$.

```{r}
prod(dnorm(x,mean=-0.36,sd=0.89))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=0.88))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=0.87))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=0.86))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=0.85))
```
```{r}
prod(dnorm(x,mean=-0.36,sd=0.84))
```

The best estimate appeared in 0.85 of stadard deviation.
In conclusion, when mean = -0.36, sd = 0.85, the likelihood estimate is close to maximum approximatly.

### Question 3:

# Consider an experiment which is a Bernoulli trial: it either succeeds with probability p or fails with probability 1−p; trials are independent of one another. 
# Throughout this question we specify a null hypothesis H_0 : p = 1/2, and an alternative hypothesis H_A : p = 2/3. 
# We perform the experiment 50 times, and our observation is r = 32 successes and 18 failures. Only one-sided tests are considered here.

> Task a

#  State the precise definition of p-value for our observation of 32 successes and state what “more extreme” means in this context.

P-value in this task represents the probability for the null hypothesis is success to obtain the observation $r=32$ or an observation more extreme.

The more extreme here means the situation when the obeservation larger than the observed sample mean.
<br><br/>

> Task b

# Calculate the p-value for the observation of 32 successes, and say whether we reject the null at the 5% level.

Calculate p-value based on null hypothesis $H_0$ : $P = 0.5$.
```{r}
pbinom(31,50,0.5,lower.tail=FALSE)
```
The p-value is about 3.2%, which is less than 5% level so we reject the null. Visually:
```{r}
x <- 0:50
plot(x,dbinom(x,50,0.5),col=c(rep("black",33),rep("red",18)),type="h",lwd=5,main="Null distribution")
legend("topleft",lty=1,lwd=2,col=c("black","red"),
legend=c("more extreme","distribution"))
```
<br><br/>

> Task c

# You will recall that the support is the logarithm of the likelihood. Can we reject H0 using the method of support?

```{r}
support <- function(m){sum(dbinom(32:50,50,0.5))}
m <- seq(from=-100,to=100,len=100) # range of plausible population means
s <- sapply(m,support) # calculate support
plot(m,s-max(s)) # subtract maximum value so support=0 at max
abline(v=mean(32:50)) # best-supported value is the sample mean
abline(h=0) # maximum support = 0
abline(h=-2) 
```
```{r}
#p <- seq(from=0, to=1, len=100)
#plot(p,dbinom(32,50,p))
```

<br><br/>

> Task d

# Devise a test of size not exceeding 1% and calculate its power.

The power of size not exceeding 1% is:
```{r}
pbinom(qbinom(0.99,50,0.5),50,2/3,lower.tail=FALSE)
```

The power is about 0.48.


